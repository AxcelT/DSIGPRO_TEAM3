import librosa
import numpy as np
import os
import matplotlib.pyplot as plt
import soundfile as sf

# Hyperparameters
energy_threshold = 0.06

# Logging Helper
def log_message(message):
    """Helper function to log messages."""
    print(f"[INFO] {message}")

# Step 1: Preprocessing
def preprocess_audio(file_path, target_sr=16000):
    """Convert audio to mono and resample to the target sampling rate."""
    log_message(f"Loading audio file: {file_path}")
    audio, sr = librosa.load(file_path, sr=None)  # Load audio with original sampling rate
    log_message(f"Original sampling rate: {sr}")
    if sr != target_sr:
        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)
        log_message(f"Audio resampled to {target_sr} Hz.")
    return audio, target_sr

# Step 2: Short Speech Detection
def detect_short_segments(audio, sr, max_duration=2, min_energy=energy_threshold, min_gap=0.5):
    """
    Detect short speech segments based on energy thresholds and duration.
    Added stricter criteria for energy and minimum gap between segments.
    """
    log_message("Detecting short speech segments...")
    frame_length = int(0.025 * sr)  # 25ms frames
    hop_length = int(0.010 * sr)   # 10ms hops
    energy = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length).flatten()
    times = librosa.frames_to_time(np.arange(len(energy)), sr=sr, hop_length=hop_length)

    short_segments = []
    segment_start = None
    for i, e in enumerate(energy):
        if e > min_energy and segment_start is None:
            segment_start = times[i]
        elif e <= min_energy and segment_start is not None:
            segment_end = times[i]
            if segment_end - segment_start <= max_duration:
                if not short_segments or (segment_start - short_segments[-1][1]) > min_gap:
                    short_segments.append((segment_start, segment_end))
                    log_message(f"Short segment detected: {segment_start:.2f}s - {segment_end:.2f}s")
            segment_start = None

    log_message(f"Total short segments detected: {len(short_segments)}")
    return short_segments

# Step 3: Save Short Segments for Subtitle Generation
def save_segments(audio, sr, segments, output_dir, base_filename, min_segment_duration=1.0):
    """Save detected short speech segments as individual audio files, ensuring minimum 1-second duration."""
    log_message(f"Saving detected segments to '{output_dir}'...")
    os.makedirs(output_dir, exist_ok=True)
    saved_files = []
    for i, (start, end) in enumerate(segments):
        start_sample = int(start * sr)
        end_sample = int(end * sr)

        # Adjust the end_sample to ensure a minimum segment duration
        if end - start < min_segment_duration:
            end_sample = start_sample + int(min_segment_duration * sr)
            # Ensure we don't exceed the audio length
            if end_sample > len(audio):
                end_sample = len(audio)

        segment_audio = audio[start_sample:end_sample]
        adjusted_end = end_sample / sr  # Adjusted end time for logging
        output_file = os.path.join(output_dir, f"{base_filename}_segment_{i+1}.wav")
        sf.write(output_file, segment_audio, sr)
        saved_files.append(output_file)
        log_message(f"Segment saved: {output_file} ({start:.2f}s - {adjusted_end:.2f}s)")
    return saved_files


# Step 4: Visualization
def plot_energy(audio, sr, energy, times, segments, output_dir, base_filename):
    """Plot the energy curve with detected segments."""
    log_message("Plotting energy curve with detected segments...")

    plt.figure(figsize=(16, 8))  # Make the plot wider by increasing the width
    plt.plot(times, energy, label="RMS Energy")
    plt.axhline(y=energy_threshold, color="red", linestyle="--", label="Energy Threshold")
    
    # Highlight detected segments
    for start, end in segments:
        plt.axvspan(start, end, color="green", alpha=0.3)

    # Customize x-axis ticks for better granularity
    max_time = times[-1]
    plt.xticks(np.arange(0, max_time + 5, 5))  # Set x-axis ticks every 5 seconds
    
    plt.xlabel("Time (s)")
    plt.ylabel("Energy")
    plt.title(f"Energy Curve for {base_filename}")
    plt.legend()
    plt.grid(True)  # Add grid to the plot

    # Save the plot
    plot_path = os.path.join(output_dir, f"{base_filename}_energy_curve.png")
    plt.savefig(plot_path)
    log_message(f"Energy curve saved: {plot_path}")
    plt.close()


# Main Script
if __name__ == "__main__":
    # Input audio file
    audio_file = r"audio\Frasier1.wav"
    base_filename = os.path.splitext(os.path.basename(audio_file))[0]

    # Output directories
    output_base_dir = r"D:\School\DSIGPRO_Project\outputs"
    segments_dir = os.path.join(output_base_dir, "segments")
    plots_dir = os.path.join(output_base_dir, "plots")

    # Ensure output directories exist
    os.makedirs(output_base_dir, exist_ok=True)
    os.makedirs(segments_dir, exist_ok=True)
    os.makedirs(plots_dir, exist_ok=True)

    # Step 1: Preprocess audio
    audio, sr = preprocess_audio(audio_file)

    # Log basic audio properties
    log_message(f"Audio Duration: {len(audio) / sr:.2f}s")
    log_message(f"Audio Sample Rate: {sr}")

    # Step 2: Detect short segments
    short_segments = detect_short_segments(audio, sr, max_duration=1.5, min_energy=0.02, min_gap=0.1)

    # Step 3: Save short segments
    if short_segments:
        saved_files = save_segments(audio, sr, short_segments, segments_dir, base_filename)
        log_message(f"Saved {len(saved_files)} short segments.")
    else:
        log_message("No short speech segments detected.")

    # Step 4: Visualize energy curve
    frame_length = int(0.025 * sr)
    hop_length = int(0.010 * sr)
    energy = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length).flatten()
    times = librosa.frames_to_time(np.arange(len(energy)), sr=sr, hop_length=hop_length)
    plot_energy(audio, sr, energy, times, short_segments, plots_dir, base_filename)

    log_message("Processing completed successfully!")
